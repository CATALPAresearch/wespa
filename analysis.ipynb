{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from src.util import prnt\n",
    "from src.util import print_all_output\n",
    "from src.settings import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.load import Load\n",
    "semester = 'SS2024'\n",
    "# Step 1\n",
    "l = Load(semester)\n",
    "l.process_textedits(filter_weeks=1)\n",
    "df = l.get_data()\n",
    "#l.run(filter_weeks=1)\n",
    "df\n",
    "# load all data of a group\n",
    "#l.run(filter_group=[2751],filter_weeks=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: EasySync"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "\n",
    "from src.extract_easy_sync import Extract_Easy_Sync\n",
    "semester = 'SS2024'\n",
    "# Step 2\n",
    "#print_all_output = False\n",
    "es = Extract_Easy_Sync(semester)\n",
    "es.is_reconstructing_text = False\n",
    "df_textchanges = es.extract_easy_sync(df)\n",
    "df_textchanges\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.1: Extract sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.extract_sessions import Extract_Sessions\n",
    "\n",
    "semester = 'SS2024'\n",
    "es = Extract_Sessions(semester)\n",
    "#dd = es.load_and_combine_df() # TODO: All authorids in the pad_commit file are derived from moodle but not from etherpad\n",
    "#dd['authorid'].unique()\n",
    "#dd[dd['authorid'].isnull()]\n",
    "df_textchanges.columns\n",
    "df_sessions = es.extract_sessions(df_textchanges)\n",
    "df_sessions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2.2: Extract and Analyze Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# TESTING ONLY\n",
    "\n",
    "from src.text_quality import Preprocess_Text_Quality\n",
    "from src.extract_easy_sync import Extract_Easy_Sync\n",
    "\n",
    "semester = 'SS2024'\n",
    "\n",
    "# Step 1: identify time breaks\n",
    "ptq = Preprocess_Text_Quality(semester)\n",
    "sft = semester_form_to_arr[semester]  # variable in settings.py\n",
    "time_breaks = ptq.split_text_progression_by_threshold(\n",
    "    #df[df['moodle_group_id']==3925], \n",
    "    df,\n",
    "    semester, \n",
    "    start_date=datetime(sft[0][0], sft[0][1], sft[0][2]), \n",
    "    end_date=datetime(sft[1][0], sft[1][1], sft[1][2]),\n",
    "    group_column='moodle_pad_id',\n",
    "    threshold_type='days'\n",
    "    )\n",
    "time_breaks.sort_values(by=['moodle_group_id', 'moodle_pad_id'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.text_quality import Preprocess_Text_Quality\n",
    "from src.extract_easy_sync import Extract_Easy_Sync\n",
    "\n",
    "semester = 'SS2024'\n",
    "timestamp_threshold_type='days'\n",
    "\n",
    "# Step 1: identify time breaks\n",
    "ptq = Preprocess_Text_Quality(semester)\n",
    "sft = semester_form_to_arr[semester]  # variable in settings.py\n",
    "time_breaks = ptq.split_text_progression_by_threshold(\n",
    "    #df[df['moodle_group_id']==3925], \n",
    "    df,\n",
    "    semester, \n",
    "    start_date=datetime(sft[0][0], sft[0][1], sft[0][2]), \n",
    "    end_date=datetime(sft[1][0], sft[1][1], sft[1][2]),\n",
    "    group_column='moodle_pad_id',\n",
    "    threshold_type=timestamp_threshold_type\n",
    "    )\n",
    "time_breaks.sort_values(by=['moodle_group_id', 'moodle_pad_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.text_quality import Preprocess_Text_Quality, Text_Quality\n",
    "from src.extract_easy_sync import Extract_Easy_Sync\n",
    "import de_core_news_sm\n",
    "\n",
    "text = \"Der Mann geht Joggen.\"\n",
    "tq = Text_Quality()\n",
    "tq.run(text, model='de_core_news_lg') # 'de_core_news_md'\n",
    "\n",
    "import de_core_news_sm\n",
    "\n",
    "nlp = de_core_news_sm.load()\n",
    "\n",
    "tokenized = nlp(text)\n",
    "for token in tokenized:\n",
    "    print(token, token.pos_, token.ent_type_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# TESTINg ONLY\n",
    "\n",
    "timestamp_threshold_type='days'\n",
    "\n",
    "es = Extract_Easy_Sync(semester, time_breaks=time_breaks)\n",
    "es.is_reconstructing_text = True\n",
    "print_all_output = True\n",
    "\n",
    "allsets = [\n",
    "    \"Z:0>12=0+12$Hello World\",\n",
    "    \"Z:12>3=6+3$you \",  \n",
    "    \"Z:15>1=10-1+1$!\",\n",
    "    \"Z:0=15|10+1$\"\n",
    "]\n",
    "\n",
    "pads = df[df['moodle_pad_id']==df['moodle_pad_id'].unique()[14]].groupby('moodle_pad_id', group_keys=True)\n",
    "#pads = df[df['moodle_pad_id']==df['moodle_pad_id'].unique()].groupby('moodle_pad_id', group_keys=True)\n",
    "\n",
    "i = 0\n",
    "for index, pad in pads:\n",
    "    print(' ')\n",
    "    for row in pad.sort_values(by=['timestamp']).itertuples():\n",
    "        i = i + 1\n",
    "        if i > 0:\n",
    "            es.extract_changeset(\n",
    "                row[5],             # row['textedit_changeset'], \n",
    "                timestamp=row[6],   # row['timestamp'], \n",
    "                group_id=row[3],    # row['moodle_group_id'], \n",
    "                pad_id=row[4],      # str(row['moodle_pad_id'])\n",
    "            )\n",
    "    print(es.ttext)\n",
    "\n",
    "\n",
    "ptq = Preprocess_Text_Quality(semester)\n",
    "res_tq = ptq.determine_text_quality_from_files(threshold_type=timestamp_threshold_type)\n",
    "res_tq\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.text_quality import Preprocess_Text_Quality\n",
    "from src.extract_easy_sync import Extract_Easy_Sync\n",
    "\n",
    "semester = 'SS2024'\n",
    "\n",
    "# Step 1: identify time breaks\n",
    "ptq = Preprocess_Text_Quality(semester)\n",
    "sft = semester_form_to_arr[semester]  # variable in settings.py\n",
    "time_breaks = ptq.split_text_progression_by_threshold(\n",
    "    #df[df['moodle_group_id']==3925], \n",
    "    df,\n",
    "    semester, \n",
    "    start_date=datetime(sft[0][0], sft[0][1], sft[0][2]), \n",
    "    end_date=datetime(sft[1][0], sft[1][1], sft[1][2]),\n",
    "    group_column='moodle_pad_id',\n",
    "    threshold_type='days'\n",
    "    )\n",
    "time_breaks.sort_values(by=['moodle_group_id', 'moodle_pad_id'])\n",
    "\n",
    "# Step 2: Extract text at the time breaks\n",
    "#df = df.dropna(subset=[\"moodle_pad_id\"])\n",
    "es = Extract_Easy_Sync(semester, time_breaks=time_breaks)\n",
    "es.is_reconstructing_text = True\n",
    "\n",
    "pads = df[df['moodle_pad_id']==df['moodle_pad_id'].unique()].groupby('moodle_pad_id', group_keys=True)\n",
    "\n",
    "i = 0\n",
    "for index, pad in pads:\n",
    "    print(' ')\n",
    "    for row in pad.sort_values(by=['timestamp']).itertuples():\n",
    "        i = i + 1\n",
    "        if i > 0:\n",
    "            es.extract_changeset(\n",
    "                row[5],             # row['textedit_changeset'], \n",
    "                timestamp=row[6],   # row['timestamp'], \n",
    "                group_id=row[3],    # row['moodle_group_id'], \n",
    "                pad_id=row[4],      # str(row['moodle_pad_id'])\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Extract text at the time breaks\n",
    "#df = df.dropna(subset=[\"moodle_pad_id\"])\n",
    "es = Extract_Easy_Sync(semester, time_breaks=time_breaks)\n",
    "es.is_reconstructing_text = True\n",
    "#pads = df[df['moodle_group_id']==df['moodle_group_id'].unique()[11]].groupby('moodle_pad_id', group_keys=True)\n",
    "pads = df[df['moodle_pad_id']==df['moodle_pad_id'].unique()[11]].groupby('moodle_pad_id', group_keys=True)\n",
    "for index, pad in pads:\n",
    "    #print(group['moodle_pad_id'])\n",
    "    for row in pad.sort_values(by=['timestamp']).itertuples():\n",
    "        #print(row[1], row[2],row[3],row[4],row[5],row[6],)\n",
    "        es.extract_changeset(\n",
    "            row[5], #row['textedit_changeset'], \n",
    "            timestamp=row[6], #row['timestamp'], \n",
    "            group_id=row[3], # row['moodle_group_id'], \n",
    "            pad_id=row[4], # str(row['moodle_pad_id'])\n",
    "        )\n",
    "    pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_textchanges = (\n",
    "    df[df['moodle_group_id']==df['moodle_group_id'].unique()[10]]\n",
    "    .groupby('moodle_pad_id', group_keys=True)  # Group by pad ID\n",
    "    .apply(\n",
    "        lambda group: group.assign(\n",
    "            week=group['timestamp'].apply(\n",
    "                lambda ts: pd.to_datetime(ts, unit='s').strftime(\"%y-%U\")\n",
    "            ),\n",
    "            **group.apply(lambda row: \n",
    "                es.extract_changeset(\n",
    "                    row['textedit_changeset'], \n",
    "                    timestamp=row['timestamp'], \n",
    "                    group_id=row['moodle_group_id'], \n",
    "                    pad_id=str(row['moodle_pad_id'])\n",
    "                ), axis=1).apply(pd.Series),\n",
    "        )\n",
    "    )\n",
    ")\n",
    "es.save_data(df_textchanges, 'textchanges.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.text_quality import Preprocess_Text_Quality\n",
    "from src.extract_easy_sync import Extract_Easy_Sync\n",
    "\n",
    "semester = 'SS2024'\n",
    "\n",
    "# Step 1: identify time breaks\n",
    "ptq = Preprocess_Text_Quality(semester)\n",
    "sft = semester_form_to_arr[semester]  # variable in settings.py\n",
    "time_breaks = ptq.split_text_progression_by_threshold(\n",
    "    df, \n",
    "    semester, \n",
    "    datetime(sft[0][0], sft[0][1], sft[0][2]), \n",
    "    datetime(sft[1][0], sft[1][1], sft[1][2]),\n",
    "    group_column='moodle_group_id',\n",
    "    threshold_type='weeks'\n",
    "    )\n",
    "time_breaks = time_breaks[['id', 'moodle_group_id', 'moodle_author_id', 'moodle_pad_id', 'timestamp']]\n",
    "\n",
    "# Step 2: Extract text at the time breaks\n",
    "#df = df.dropna(subset=[\"moodle_pad_id\"])\n",
    "es = Extract_Easy_Sync(semester, time_breaks=time_breaks)\n",
    "es.is_reconstructing_text = True\n",
    "df_textchanges = es.extract_easy_sync(df)\n",
    "df_textchanges\n",
    "\n",
    "# Step 3: Compute text features\n",
    "df_raw_text = pd.read_csv(f'{output_path}{project_name}-{semester}-02.1-text-revisions.csv')\n",
    "df_raw_text.columns = [\n",
    "    \"group_id\", \n",
    "    \"pad_id\",\n",
    "    \"timestamp\", \n",
    "    \"current_time_threshold\",\n",
    "    \"text\",\n",
    "]\n",
    "res = ptq.determine_text_quality(df_raw_text) # will be saved to file 2.2\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "#df_raw_text = pd.read_csv(f'{output_path}{project_name}-{semester}-02.1-text-revisions.csv')\n",
    "df_raw_text = pd.read_csv(f'{output_path}{project_name}-{semester}-02.1-text-quality-new.csv')\n",
    "df_raw_text.columns = [\n",
    "    \"group_id\", \n",
    "    \"pad_id\",\n",
    "    \"timestamp\", \n",
    "    \"current_time_threshold\",\n",
    "    \"text\",\n",
    "]\n",
    "print(\n",
    "    len(df_raw_text['group_id'].unique()),\n",
    "    len(df_raw_text['timestamp'].unique()),\n",
    "    df_raw_text.text.str.len().mean(),\n",
    "    df_raw_text.shape[0]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 : Extract_Neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "from src.extract_neighbours import Extract_Neighbours\n",
    "\n",
    "# Step 3\n",
    "print_all_output=False\n",
    "semester = 'SS2024'\n",
    "en = Extract_Neighbours(semester)\n",
    "author_relations = en.extract_neighbours(df_textchanges)\n",
    "author_relations\n",
    "\n",
    "#author_relations[author_relations['right_neighbor']>0]\n",
    "#df_textchanges['moodle_pad_id_'] = df_textchanges['moodle_pad_id'].str.split('$', expand=True)[0]\n",
    "#pads = df_textchanges['moodle_pad_id_'].unique()\n",
    "#df_textchanges[df_textchanges['moodle_pad_id_'] == pads[3]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Extract_Degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from src.extract_degrees import Extract_Degree\n",
    "\n",
    "# Step 4\n",
    "semester = 'SS2024'\n",
    "ed = Extract_Degree(semester)\n",
    "author_relations_summary = ed.summarize_individual_level(author_relations)\n",
    "\n",
    "#author_relations_summary\n",
    "#author_relations_summary['right2'] = author_relations_summary['right'].astype('int').abs() \n",
    "#author_relations_summary['right2']\n",
    "#author_relations_summary.dtypes\n",
    "\n",
    "print_all_output = False #True\n",
    "author_degrees = ed.extract_degree(author_relations_summary)\n",
    "# TODO: During the processing the size of the dataframe varys pretty much. Something is wrong with the agg function. Check if this behavior is ok.\n",
    "#print(author_relations_summary.size)\n",
    "#print(author_degrees.size)\n",
    "#author_degrees\n",
    "\n",
    "print_all_output = True\n",
    "author_degrees_per_group = ed.map_to_group(df_textchanges, author_degrees)\n",
    "#print('df_textchanges', df_textchanges)\n",
    "#print('author_degrees', author_degrees)\n",
    "#author_degrees_per_group[author_degrees_per_group['indegree_count']>0]\n",
    "author_degrees_per_group\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Coll Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.collaboration_graph import Collaboration_Graph\n",
    "\n",
    "semester = 'SS2024'\n",
    "cg = Collaboration_Graph(semester)\n",
    "#cg.check_random_group(author_relations)\n",
    "graph_measures = cg.create_graph_for_all_groups(author_relations, save_plot=False, save_output=True, show_plot=False)\n",
    "graph_measures\n",
    "#cg.create_json_graph_for_all_groups(author_relations, last_modified = 1733786132)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Run over all semesters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process semester SS2024\n",
      "['24-16', '24-17'] ['24-18', '24-19', '24-20'] ['24-21', '24-22', '24-23']\n",
      "Loading textedit data from CSV\n",
      "step2\n",
      "New Pad: g.0PgLGP5fOtwMsIuq$ex_42_g_3942_66386e23a6039\n",
      "New Pad: g.0PgLGP5fOtwMsIuq$ex_43_g_3942_66392ec2b0d0e\n",
      "New Pad: g.0PgLGP5fOtwMsIuq$ex_44_g_3942_665466a67e4ca\n",
      "New Pad: g.0PgLGP5fOtwMsIuq$ex_45_g_3942_66546d1bb607c\n",
      "New Pad: g.1FQ5Zyb0qCNzDKf4$ex_42_g_3934_663834f183e52\n",
      "New Pad: g.1FQ5Zyb0qCNzDKf4$ex_43_g_3934_66383e1ce7e2a\n",
      "New Pad: g.1FQ5Zyb0qCNzDKf4$ex_44_g_3934_665d7ee6bb98e\n",
      "New Pad: g.1FQ5Zyb0qCNzDKf4$ex_45_g_3934_665d7f20b5ed9\n",
      "New Pad: g.1GtHFyAvceNMlwOS$ex_42_g_3929_663a072073963\n",
      "New Pad: g.1GtHFyAvceNMlwOS$ex_43_g_3929_66388aecdbb8b\n",
      "New Pad: g.1GtHFyAvceNMlwOS$ex_44_g_3929_6653de9c72a94\n",
      "New Pad: g.1GtHFyAvceNMlwOS$ex_45_g_3929_66569429a360d\n",
      "New Pad: g.4QjLiS7j7tsAzOcp$ex_42_g_3970_663ce46cd4ba5\n",
      "New Pad: g.4QjLiS7j7tsAzOcp$ex_43_g_3970_663ce4a0324ce\n",
      "New Pad: g.4QjLiS7j7tsAzOcp$ex_44_g_3970_665da9f2a7bbb\n",
      "New Pad: g.4QjLiS7j7tsAzOcp$ex_45_g_3970_666051cb3ab40\n",
      "New Pad: g.9dTA6LIuh8622uD0$ex_42_g_3930_664c95b9cb53d\n",
      "New Pad: g.9dTA6LIuh8622uD0$ex_43_g_3930_664c4dbe1bf9c\n",
      "New Pad: g.9dTA6LIuh8622uD0$ex_44_g_3930_665b5156c603a\n",
      "New Pad: g.9dTA6LIuh8622uD0$ex_45_g_3930_665b5154e014f\n",
      "New Pad: g.IQ82IwG4tXenx3a6$ex_42_g_3926_6638a3cf4f3fe\n",
      "New Pad: g.IQ82IwG4tXenx3a6$ex_43_g_3926_663d1a30960ee\n",
      "New Pad: g.IQ82IwG4tXenx3a6$ex_44_g_3926_66547431008e3\n",
      "New Pad: g.IQ82IwG4tXenx3a6$ex_45_g_3926_665476483a2ff\n",
      "New Pad: g.JUigqFdVQKa78OMY$ex_42_g_3960_6638c72c3b64d\n",
      "New Pad: g.JUigqFdVQKa78OMY$ex_43_g_3960_664089420d605\n",
      "New Pad: g.JUigqFdVQKa78OMY$ex_44_g_3960_66542494d3a7d\n",
      "New Pad: g.JUigqFdVQKa78OMY$ex_45_g_3960_66572b2801414\n",
      "New Pad: g.Js2JEFlvdoqew9Wy$ex_42_g_3922_662a187e7fa31\n",
      "New Pad: g.Js2JEFlvdoqew9Wy$ex_43_g_3922_663ccea6e39a1\n",
      "New Pad: g.Js2JEFlvdoqew9Wy$ex_44_g_3922_665479219508d\n",
      "New Pad: g.Js2JEFlvdoqew9Wy$ex_45_g_3922_665858e98c993\n",
      "New Pad: g.KrfqBYCOCthaoEn5$ex_42_g_3957_6641d1789fa8d\n",
      "New Pad: g.KrfqBYCOCthaoEn5$ex_43_g_3957_664a611b1205b\n",
      "New Pad: g.KrfqBYCOCthaoEn5$ex_44_g_3957_6661986145799\n",
      "New Pad: g.MD5Bv2gjV0fQ499r$ex_42_g_3938_6638b4295c429\n",
      "New Pad: g.MD5Bv2gjV0fQ499r$ex_43_g_3938_664102aceeeba\n",
      "New Pad: g.MD5Bv2gjV0fQ499r$ex_44_g_3938_66548a201ce73\n",
      "New Pad: g.MD5Bv2gjV0fQ499r$ex_45_g_3938_665c6ff0c1a86\n",
      "New Pad: g.ME3g1L0HgIZoWwep$ex_42_g_3923_662a18a5f0ee4\n",
      "New Pad: g.ME3g1L0HgIZoWwep$ex_43_g_3923_663b44d9e1d0e\n",
      "New Pad: g.ME3g1L0HgIZoWwep$ex_44_g_3923_6654112b94b60\n",
      "New Pad: g.ME3g1L0HgIZoWwep$ex_45_g_3923_665c8956db085\n",
      "New Pad: g.MbV4iCtKPi0lmieN$ex_42_g_3924_662a18c172bbd\n",
      "New Pad: g.MbV4iCtKPi0lmieN$ex_43_g_3924_66506ae82202d\n",
      "New Pad: g.Mn6eox7i3iATWD6v$ex_42_g_3951_66409f1ebce9e\n",
      "New Pad: g.Mn6eox7i3iATWD6v$ex_43_g_3951_66409f208d987\n",
      "New Pad: g.Mn6eox7i3iATWD6v$ex_44_g_3951_6654cc0708c66\n",
      "New Pad: g.Mn6eox7i3iATWD6v$ex_45_g_3951_6654cc0d241c3\n",
      "New Pad: g.NKbLD6ZfzUFcpELR$ex_42_g_3932_6638f46db9c2f\n",
      "New Pad: g.NKbLD6ZfzUFcpELR$ex_43_g_3932_663a1de4c23ca\n",
      "New Pad: g.NKbLD6ZfzUFcpELR$ex_44_g_3932_6655938a4e3be\n",
      "New Pad: g.NKbLD6ZfzUFcpELR$ex_45_g_3932_66561fe3a8db1\n",
      "New Pad: g.NNEiXgyv7JZhmvSo$ex_42_g_3968_6639f79ad7651\n",
      "New Pad: g.NNEiXgyv7JZhmvSo$ex_43_g_3968_6644b2693a298\n",
      "New Pad: g.Ovupf9RvfDcoJH2e$ex_42_g_3944_6638abf5ca4d1\n",
      "New Pad: g.Ovupf9RvfDcoJH2e$ex_43_g_3944_6638cf3816b54\n",
      "New Pad: g.Ovupf9RvfDcoJH2e$ex_44_g_3944_665421261fb0a\n",
      "New Pad: g.Ovupf9RvfDcoJH2e$ex_45_g_3944_665421901cf5e\n",
      "New Pad: g.QYR7LkuHF88FZH1Q$ex_42_g_3954_66392a84d4f27\n",
      "New Pad: g.QYR7LkuHF88FZH1Q$ex_43_g_3954_66392bf9be4fa\n",
      "New Pad: g.QYR7LkuHF88FZH1Q$ex_44_g_3954_6654455e308c6\n",
      "New Pad: g.QYR7LkuHF88FZH1Q$ex_45_g_3954_6659fca92f520\n",
      "New Pad: g.UQq8EpNJQcDrzYGL$ex_42_g_3937_663a1a2d6ebf6\n",
      "New Pad: g.UQq8EpNJQcDrzYGL$ex_43_g_3937_66499853841da\n",
      "New Pad: g.UQq8EpNJQcDrzYGL$ex_44_g_3937_665c5f48f2e9f\n",
      "New Pad: g.UQq8EpNJQcDrzYGL$ex_45_g_3937_665c5f4700738\n",
      "New Pad: g.VNXnrVqwmNWNPVIs$ex_42_g_3943_6638e61862f87\n",
      "New Pad: g.VNXnrVqwmNWNPVIs$ex_43_g_3943_663e0620d9384\n",
      "New Pad: g.VNXnrVqwmNWNPVIs$ex_44_g_3943_665899d0c1d74\n",
      "New Pad: g.VNXnrVqwmNWNPVIs$ex_45_g_3943_665e2b3dabca9\n",
      "New Pad: g.VOh6vgHSkUXimyS5$ex_42_g_3940_6638a9572ddc1\n",
      "New Pad: g.VOh6vgHSkUXimyS5$ex_43_g_3940_663b24dde871f\n",
      "New Pad: g.VOh6vgHSkUXimyS5$ex_44_g_3940_6654b1fa65efa\n",
      "New Pad: g.VOh6vgHSkUXimyS5$ex_45_g_3940_665b3dec93b6e\n",
      "New Pad: g.WC4tPgjkXhAiLKhN$ex_42_g_3946_6639549395d16\n",
      "New Pad: g.WC4tPgjkXhAiLKhN$ex_43_g_3946_6639560305f6c\n",
      "New Pad: g.WC4tPgjkXhAiLKhN$ex_44_g_3946_6654e99e68c83\n",
      "New Pad: g.WC4tPgjkXhAiLKhN$ex_45_g_3946_665de649cb0ec\n",
      "New Pad: g.WLxHPcchxDNgcGCf$ex_42_g_3967_6638cedea7ebd\n",
      "New Pad: g.WLxHPcchxDNgcGCf$ex_43_g_3967_6638d57b28897\n",
      "New Pad: g.WLxHPcchxDNgcGCf$ex_44_g_3967_66559749aee03\n",
      "New Pad: g.WLxHPcchxDNgcGCf$ex_45_g_3967_6655ccace8a38\n",
      "New Pad: g.WSZHSWoCBwdEkGq7$ex_42_g_3927_66391bbf9698c\n",
      "New Pad: g.WSZHSWoCBwdEkGq7$ex_43_g_3927_663d01cb06495\n",
      "New Pad: g.WSZHSWoCBwdEkGq7$ex_44_g_3927_6654225a15fb6\n",
      "New Pad: g.WSZHSWoCBwdEkGq7$ex_45_g_3927_6654225cf2f1f\n",
      "New Pad: g.WYOFFZwudeI5CJVn$ex_42_g_3928_663920b7d9424\n",
      "New Pad: g.WYOFFZwudeI5CJVn$ex_43_g_3928_6639cdf90301c\n",
      "New Pad: g.WYOFFZwudeI5CJVn$ex_44_g_3928_665b770dd88f6\n",
      "New Pad: g.WYOFFZwudeI5CJVn$ex_45_g_3928_665b9b8ae4959\n",
      "New Pad: g.WyegUIV1yqcoOiU3$ex_42_g_3931_663fe6caaf2f0\n",
      "New Pad: g.WyegUIV1yqcoOiU3$ex_43_g_3931_664123c0978c7\n",
      "New Pad: g.WyegUIV1yqcoOiU3$ex_44_g_3931_6654d5d238713\n",
      "New Pad: g.WyegUIV1yqcoOiU3$ex_45_g_3931_665dcebc2ce29\n",
      "New Pad: g.XNSDKf6MnHl90j8I$ex_42_g_3945_6645ed6f3bfab\n",
      "New Pad: g.XNSDKf6MnHl90j8I$ex_43_g_3945_6645ed713d71c\n",
      "New Pad: g.XNSDKf6MnHl90j8I$ex_44_g_3945_665dc7a1673ab\n",
      "New Pad: g.XNSDKf6MnHl90j8I$ex_45_g_3945_666d801cc99c7\n",
      "New Pad: g.XdjeLmhujsAkgSlg$ex_42_g_3952_66409c03c3580\n",
      "New Pad: g.XdjeLmhujsAkgSlg$ex_43_g_3952_6640a16ea0894\n",
      "New Pad: g.XdjeLmhujsAkgSlg$ex_44_g_3952_6654a740e974f\n",
      "New Pad: g.XdjeLmhujsAkgSlg$ex_45_g_3952_666c5eee06115\n",
      "New Pad: g.YTkHvADDJMbnWs11$ex_42_g_3925_6638f7a20cf04\n",
      "New Pad: g.YTkHvADDJMbnWs11$ex_43_g_3925_6638fd605a6c2\n",
      "New Pad: g.YTkHvADDJMbnWs11$ex_44_g_3925_66540b3082b14\n",
      "New Pad: g.YTkHvADDJMbnWs11$ex_45_g_3925_66540be01c553\n",
      "New Pad: g.aMxiUzK58giNlR3z$ex_42_g_3953_663a723169241\n",
      "New Pad: g.aMxiUzK58giNlR3z$ex_43_g_3953_6653738411314\n",
      "New Pad: g.alTpdI0ehccCZQPJ$ex_42_g_3949_6638848e2b39b\n",
      "New Pad: g.alTpdI0ehccCZQPJ$ex_43_g_3949_663a492205555\n",
      "New Pad: g.alTpdI0ehccCZQPJ$ex_44_g_3949_66546180a41a2\n",
      "New Pad: g.alTpdI0ehccCZQPJ$ex_45_g_3949_6654695065aa3\n",
      "New Pad: g.idYNnuxzL7MRZnaH$ex_42_g_3947_663881e7d4d56\n",
      "New Pad: g.idYNnuxzL7MRZnaH$ex_43_g_3947_663c75682ebe4\n",
      "New Pad: g.idYNnuxzL7MRZnaH$ex_44_g_3947_6654627446045\n",
      "New Pad: g.idYNnuxzL7MRZnaH$ex_45_g_3947_665463fc8cdf1\n",
      "New Pad: g.lDop5wSjBvTn23QD$ex_42_g_3963_66411b7438510\n",
      "New Pad: g.lDop5wSjBvTn23QD$ex_43_g_3963_66425c2d77076\n",
      "New Pad: g.lDop5wSjBvTn23QD$ex_44_g_3963_665747d33dab9\n",
      "New Pad: g.lDop5wSjBvTn23QD$ex_45_g_3963_665747eb94b40\n",
      "New Pad: g.m0DvgBpGcSQrBDjA$ex_42_g_3969_66392375bda7e\n",
      "New Pad: g.m0DvgBpGcSQrBDjA$ex_43_g_3969_664dc400acb5a\n",
      "New Pad: g.m0DvgBpGcSQrBDjA$ex_44_g_3969_6662f1c866aed\n",
      "New Pad: g.m0DvgBpGcSQrBDjA$ex_45_g_3969_6662f6a831109\n",
      "New Pad: g.nARpuWujNTjd3J29$ex_42_g_3936_6638a77969c7a\n",
      "New Pad: g.nARpuWujNTjd3J29$ex_43_g_3936_6638a7a80bc96\n",
      "New Pad: g.nARpuWujNTjd3J29$ex_44_g_3936_66541ebf0745a\n",
      "New Pad: g.nARpuWujNTjd3J29$ex_45_g_3936_66541ee93c3c1\n",
      "New Pad: g.ngeassBsT0Unwuer$ex_42_g_3933_663b889783ff0\n",
      "New Pad: g.ngeassBsT0Unwuer$ex_43_g_3933_6647810a3cb4d\n",
      "New Pad: g.ngeassBsT0Unwuer$ex_44_g_3933_665ca3032c9fa\n",
      "New Pad: g.ngeassBsT0Unwuer$ex_45_g_3933_6660330c79a3a\n",
      "New Pad: g.npGysd4IMoyYlPHn$ex_42_g_3948_6640fa0eb0ee7\n",
      "New Pad: g.npGysd4IMoyYlPHn$ex_43_g_3948_664a60e6400a0\n",
      "New Pad: g.npGysd4IMoyYlPHn$ex_44_g_3948_6655cb178b84b\n",
      "New Pad: g.npGysd4IMoyYlPHn$ex_45_g_3948_6668bb7100f9a\n",
      "New Pad: g.qPhqaykO58VxA4Dp$ex_42_g_3959_663897f9dcdec\n",
      "New Pad: g.qPhqaykO58VxA4Dp$ex_43_g_3959_66405d3b7c5f5\n",
      "New Pad: g.qPhqaykO58VxA4Dp$ex_44_g_3959_6654a84f8199a\n",
      "New Pad: g.qPhqaykO58VxA4Dp$ex_45_g_3959_6654e85b1985b\n",
      "New Pad: g.s4mU1gZtyAB7616v$ex_42_g_3955_663a431b6189d\n",
      "New Pad: g.s4mU1gZtyAB7616v$ex_43_g_3955_66467bfd2d6fd\n",
      "New Pad: g.s4mU1gZtyAB7616v$ex_44_g_3955_6656d1250829f\n",
      "New Pad: g.s4mU1gZtyAB7616v$ex_45_g_3955_6658a03cedf01\n",
      "New Pad: g.s5DawphZPK4HfysD$ex_42_g_3965_66387e42c8edc\n",
      "New Pad: g.s5DawphZPK4HfysD$ex_43_g_3965_664358b57f115\n",
      "New Pad: g.s5DawphZPK4HfysD$ex_44_g_3965_665cafa007d94\n",
      "New Pad: g.s5DawphZPK4HfysD$ex_45_g_3965_665cb0541f703\n",
      "New Pad: g.sNyCjtx7eO6EGZxb$ex_42_g_3935_6638a4c859e19\n",
      "New Pad: g.sNyCjtx7eO6EGZxb$ex_43_g_3935_6638a6e6996ff\n",
      "New Pad: g.sNyCjtx7eO6EGZxb$ex_44_g_3935_6659decdc013c\n",
      "New Pad: g.sNyCjtx7eO6EGZxb$ex_45_g_3935_6659e09faa03a\n",
      "New Pad: g.srTHL2gdceq8Ax3E$ex_42_g_3939_6639c17d6a8f2\n",
      "New Pad: g.srTHL2gdceq8Ax3E$ex_43_g_3939_6639cb5362643\n",
      "New Pad: g.srTHL2gdceq8Ax3E$ex_44_g_3939_6654d41405090\n",
      "New Pad: g.srTHL2gdceq8Ax3E$ex_45_g_3939_6654d428d224a\n",
      "New Pad: g.ur7FAATrj4Et7Tjp$ex_42_g_3950_663882c0eedd6\n",
      "New Pad: g.ur7FAATrj4Et7Tjp$ex_43_g_3950_663ba4f3205c1\n",
      "New Pad: g.ur7FAATrj4Et7Tjp$ex_44_g_3950_665877b9ab58a\n",
      "New Pad: g.ur7FAATrj4Et7Tjp$ex_45_g_3950_665f08b77f254\n",
      "New Pad: g.vMp1JC3uxVwS45mN$ex_42_g_3920_662a17b522fd0\n",
      "New Pad: g.vMp1JC3uxVwS45mN$ex_43_g_3920_663aa3ee9183b\n",
      "New Pad: g.vMp1JC3uxVwS45mN$ex_44_g_3920_6655f4dd38081\n",
      "New Pad: g.vMp1JC3uxVwS45mN$ex_45_g_3920_665673ad92602\n",
      "New Pad: g.vQetj3X8zQZebMGZ$ex_42_g_3961_663a2e68bed51\n",
      "New Pad: g.vQetj3X8zQZebMGZ$ex_43_g_3961_663e6298e604b\n",
      "New Pad: g.vQetj3X8zQZebMGZ$ex_44_g_3961_665eaf3f2cdf7\n",
      "New Pad: g.vQetj3X8zQZebMGZ$ex_45_g_3961_665eafbe3a40e\n",
      "New Pad: g.vxdLPyxyZ5dnb6Nc$ex_42_g_3964_6638a7b19a79b\n",
      "New Pad: g.vxdLPyxyZ5dnb6Nc$ex_43_g_3964_664b6b2e1806b\n",
      "New Pad: g.vxdLPyxyZ5dnb6Nc$ex_44_g_3964_665497df5132b\n",
      "New Pad: g.vxdLPyxyZ5dnb6Nc$ex_45_g_3964_6654d6e3a8e32\n",
      "New Pad: g.wpR2USYw4BYDdyso$ex_42_g_3966_663a7373110da\n",
      "New Pad: g.wpR2USYw4BYDdyso$ex_43_g_3966_663a7427a695b\n",
      "New Pad: g.xxE4v5e78qDz5RWR$ex_42_g_3941_6638ad1b21168\n",
      "New Pad: g.xxE4v5e78qDz5RWR$ex_43_g_3941_6641c359656a3\n",
      "New Pad: g.xxE4v5e78qDz5RWR$ex_44_g_3941_6660c21cf02ea\n",
      "New Pad: g.xxE4v5e78qDz5RWR$ex_45_g_3941_6660c25a8aa13\n",
      "New Pad: g.z1norr9R92aaxiKZ$ex_42_g_3921_662a18595e8ea\n",
      "New Pad: g.z1norr9R92aaxiKZ$ex_43_g_3921_663fdd47f4061\n",
      "New Pad: g.z1norr9R92aaxiKZ$ex_44_g_3921_6654283269bc5\n",
      "New Pad: g.z1norr9R92aaxiKZ$ex_45_g_3921_6654281d42972\n",
      "New Pad: g.zlwaNRtzA0RDAFPs$ex_42_g_3958_66387b5f03930\n",
      "New Pad: g.zlwaNRtzA0RDAFPs$ex_43_g_3958_663fb61ba955a\n",
      "New Pad: g.zlwaNRtzA0RDAFPs$ex_44_g_3958_66559927e7a3d\n",
      "New Pad: g.zlwaNRtzA0RDAFPs$ex_45_g_3958_665dc664684b6\n",
      "step3 Extract Sessions (skipped)\n",
      "step4 - Extract Text Versions\n",
      "date thresholds [1.7119224e+09 1.7125272e+09 1.7131320e+09 1.7137368e+09 1.7143416e+09\n",
      " 1.7149464e+09 1.7155512e+09 1.7161560e+09 1.7167608e+09 1.7173656e+09\n",
      " 1.7179704e+09 1.7185752e+09 1.7191800e+09 1.7197848e+09 1.7203896e+09\n",
      " 1.7209944e+09 1.7215992e+09 1.7222040e+09 1.7228088e+09 1.7234136e+09\n",
      " 1.7240184e+09 1.7246232e+09 1.7252280e+09 1.7258328e+09 1.7264376e+09\n",
      " 1.7270424e+09 1.7276472e+09]\n",
      "step5.1 - Extract_Neighbours\n",
      "step5.2 - Extract Degree\n",
      "step6 - Collaboration_Graph\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nise/Documents/proj_001_doc/pub/93-2024-CSCW-WritingAnalytics/wesepa/src/collaboration_graph.py:209: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  plt.figure(figsize=(10, 10))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step5.1 - Extract_Neighbours\n",
      "step5.2 - Extract Degree\n",
      "step6 - Collaboration_Graph\n",
      "step5.1 - Extract_Neighbours\n",
      "step5.2 - Extract Degree\n",
      "step6 - Collaboration_Graph\n",
      "step5.1 - Extract_Neighbours\n",
      "step5.2 - Extract Degree\n",
      "step6 - Collaboration_Graph\n",
      "step5.1 - Extract_Neighbours\n"
     ]
    }
   ],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\"\"\"Step 0: Run over all semesters\"\"\"\n",
    "import gc  # Import garbage collector\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from src.util import prnt\n",
    "from src.util import print_all_output\n",
    "from src.settings import *\n",
    "from src.load import Load\n",
    "from src.extract_easy_sync import Extract_Easy_Sync\n",
    "from src.extract_sessions import Extract_Sessions\n",
    "from src.extract_neighbours import Extract_Neighbours\n",
    "from src.extract_degrees import Extract_Degree\n",
    "from src.collaboration_graph import Collaboration_Graph\n",
    "from src.text_quality import Preprocess_Text_Quality\n",
    "\n",
    "semesters = [\n",
    "    # not available # 'SS2021', \n",
    "    #('WS2021_22', 'dump20240826'),\n",
    "    #('SS2022', 'dump20240826'),\n",
    "    #('WS2022_23', 'dump20240826'),\n",
    "    #('SS2023', 'dump20240826'),\n",
    "    #('WS2023_24', 'dump20240826'),\n",
    "    ('SS2024', 'dump20240826'),\n",
    "    #('WS2024_25', 'dump20241209'),\n",
    "]\n",
    "threshold = 'weeks'\n",
    "print_all_output = False\n",
    "compute_texts = False\n",
    "for the_semester in semesters:\n",
    "    print('Process semester '+ the_semester[0])\n",
    "    semester = the_semester[0]\n",
    "    the_dump = the_semester[1]\n",
    "    period_1 = get_period(semester, period_1_arr)\n",
    "    period_2 = get_period(semester, period_2_arr)\n",
    "    period_3 = get_period(semester, period_3_arr)\n",
    "    print(period_1, period_2, period_3)\n",
    "    # Step 1\n",
    "    l = Load(semester, the_dump)\n",
    "    #l.run()\n",
    "    l.process_textedits(filter_weeks=1)\n",
    "    df = l.get_data()\n",
    "    \n",
    "    # Step 2\n",
    "    # Step 2.1: identify time breaks\n",
    "    ptq = Preprocess_Text_Quality(semester)\n",
    "    sft = semester_form_to_arr[semester]  # variable in settings.py\n",
    "    time_breaks = ptq.split_text_progression_by_threshold(\n",
    "        #df[df['moodle_group_id']==3925], \n",
    "        df,\n",
    "        semester, \n",
    "        start_date=datetime(sft[0][0], sft[0][1], sft[0][2]), \n",
    "        end_date=datetime(sft[1][0], sft[1][1], sft[1][2]),\n",
    "        group_column='moodle_pad_id',\n",
    "        threshold_type=threshold\n",
    "        )\n",
    "    time_breaks.sort_values(by=['moodle_group_id', 'moodle_pad_id'])\n",
    "    \n",
    "    # Step 2.2 Extract changesets\n",
    "    print('step2')\n",
    "    es = Extract_Easy_Sync(semester, time_breaks)\n",
    "    es.is_reconstructing_text = compute_texts\n",
    "    df_textchanges = es.extract_easy_sync(df)\n",
    "    del df  # Free memory\n",
    "    gc.collect()  # Force garbage collection\n",
    "    \n",
    "    # Step 3\n",
    "    print('step3 Extract Sessions (skipped)')\n",
    "    ##es = Extract_Sessions(semester)\n",
    "    ##df_sessions = es.extract_sessions(df_textchanges)\n",
    "    \n",
    "    # Step 4\n",
    "    print('step4 - Extract Text Versions')\n",
    "    if compute_texts == True:\n",
    "        all_text = pd.read_csv(f'{output_path}{project_name}-{semester}-02.1-text-revisions.csv')\n",
    "        ptq = Preprocess_Text_Quality(semester)\n",
    "        sft = semester_form_to_arr[semester]  # variable in settings.py\n",
    "        df_raw_text = ptq.split_text_progression_by_threshold(\n",
    "            all_text, \n",
    "            semester, \n",
    "            datetime(sft[0][0], sft[0][1], sft[0][2]), \n",
    "            datetime(sft[1][0], sft[1][1], sft[1][2])\n",
    "            )\n",
    "        res = ptq.determine_text_quality(df_raw_text) # will be saved to file 2.2\n",
    "    \n",
    "    \n",
    "    en = Extract_Neighbours(semester, threshold)\n",
    "    ed = Extract_Degree(semester, threshold)\n",
    "    df_textchanges['timestamp'] = df_textchanges['timestamp'].astype(float)\n",
    "    date_thresholds = es.generate_observation_times(\n",
    "        datetime(sft[0][0], sft[0][1], sft[0][2]), \n",
    "        datetime(sft[1][0], sft[1][1], sft[1][2]),\n",
    "        threshold_type=threshold\n",
    "        )\n",
    "    print('date thresholds', date_thresholds)\n",
    "    for subset_until in date_thresholds:# [date_thresholds[len(date_thresholds)-2]]:\n",
    "        df_textchanges_until_break = df_textchanges[df_textchanges['timestamp'] < subset_until]\n",
    "        if df_textchanges_until_break.empty:\n",
    "            continue\n",
    "        \n",
    "        print('step5.1 - Extract_Neighbours')\n",
    "        author_relations = en.extract_neighbours(df_textchanges_until_break, subset_until) # before: df_textchanges xxx\n",
    "        \n",
    "        print('step5.2 - Extract Degree')\n",
    "        author_relations_summary = ed.summarize_individual_level(author_relations, subset_until)\n",
    "        author_degrees = ed.extract_degree(author_relations_summary, subset_until)\n",
    "        author_degrees_per_group = ed.map_to_group(df_textchanges_until_break, author_degrees, subset_until)  \n",
    "        del df_textchanges_until_break, author_degrees_per_group, author_relations_summary\n",
    "        gc.collect()\n",
    "        \n",
    "        print('step6 - Collaboration_Graph')\n",
    "        cg = Collaboration_Graph(semester, threshold)\n",
    "        graph_measures = cg.create_graph_for_all_groups(author_relations, subset_until, save_plot=True, save_output=True, show_plot=False)\n",
    "        del author_relations, author_degrees, cg, graph_measures\n",
    "        gc.collect()\n",
    "    # fin\n",
    "\n",
    "    del df_textchanges\n",
    "    gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_textchanges_until_break\n",
    "#author_degrees\n",
    "#author_relations\n",
    "date_thresholds = np.array(date_thresholds)\n",
    "for i in date_thresholds:\n",
    "        df_textchanges_until_break = df_textchanges[df_textchanges['timestamp'] < i]\n",
    "        if df_textchanges_until_break.empty:\n",
    "            #print(i)\n",
    "            continue\n",
    "        print(df_textchanges_until_break.shape[0])\n",
    "\n",
    "#df_textchanges[df_textchanges['timestamp'] < max(date_thresholds)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Example usage\n",
    "# Create a test directed graph\n",
    "G = nx.DiGraph()\n",
    "G.add_edges_from([\n",
    "    (1, 2, {'weight': 3}),\n",
    "    (2, 3, {'weight': 5}),\n",
    "    (3, 4, {'weight': 2}),\n",
    "    (4, 1, {'weight': 4}),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 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\n",
    "from huggingface_hub import notebook_login\n",
    "#notebook_login()\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline\n",
    "import logging\n",
    "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "# Example text\n",
    "text1 = \"Renewable energy is the future.\"\n",
    "text2 = \"However, it cannot fully replace fossil fuels due to reliability issues.\"\n",
    "text1 = \"Earth is not flat\"\n",
    "text2 = \"Der Hahn krÃ¤ht\"\n",
    "text2 = \"Atomar power is not safe\"\n",
    "\n",
    "# Detect fake news\n",
    "model_name = \"openai-community/roberta-base-openai-detector\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "pipe = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "result = pipe(text1)\n",
    "print(result)\n",
    "\n",
    "# Relation classification model\n",
    "relation_pipeline = pipeline(\"text-classification\", model=\"raruidol/ArgumentMining-EN-ARI-AIF-RoBERTa_L\")\n",
    "result = relation_pipeline(f\"{text1} [SEP] {text2}\")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install spacy\n",
    "#!pip install textdescriptives\n",
    "#!spacy download en_core_web_sm\n",
    "import spacy\n",
    "import textdescriptives as td\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp.add_pipe(\"textdescriptives/quality\")\n",
    "doc = nlp(\"The world is changed. I feel it in the \\n water. I feel it in\\n the earth. I smell it in the air. Much that once was is lost, for none now live who remember it.\")\n",
    "\n",
    "# all attributes are stored as a dict in the ._.quality attribute\n",
    "doc._.quality\n",
    "# check if the document passed all quality checks\n",
    "doc._.passed_quality_check\n",
    "\n",
    "# extract to dataframe\n",
    "td.extract_df(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
